# Geodesyxx Paper Reproduction Requirements
# Python 3.8+ compatible package versions
# Tested on Apple M2 Pro, Linux, and Windows systems

# Core Dependencies
torch>=2.0.0,<3.0.0
numpy>=1.21.0,<2.0.0
scipy>=1.8.0,<2.0.0
pandas>=1.4.0,<3.0.0

# Transformer Models and NLP
transformers>=4.25.0,<5.0.0
datasets>=2.8.0,<3.0.0
tokenizers>=0.13.0,<1.0.0
huggingface-hub>=0.12.0,<1.0.0
safetensors>=0.3.0,<1.0.0

# Machine Learning Utilities
scikit-learn>=1.2.0,<2.0.0
matplotlib>=3.5.0,<4.0.0
seaborn>=0.11.0,<1.0.0
tqdm>=4.64.0,<5.0.0

# Statistical Analysis
statsmodels>=0.13.0,<1.0.0
pingouin>=0.5.0,<1.0.0  # Advanced statistical tests

# Configuration Management
pyyaml>=6.0,<7.0
omegaconf>=2.3.0,<3.0.0  # Structured configs

# Embeddings and Language Resources
# Note: GloVe vectors should be downloaded separately
# wget http://nlp.stanford.edu/data/glove.6B.zip

# Optional: NLTK for WordNet (Phase 1-3)
nltk>=3.8,<4.0  # For WordNet hypernym pairs

# Development and Testing
pytest>=7.0.0,<8.0.0
pytest-cov>=4.0.0,<5.0.0
black>=22.0.0,<24.0.0  # Code formatting
isort>=5.10.0,<6.0.0  # Import sorting

# Memory Profiling (Optional)
psutil>=5.9.0,<6.0.0
memory-profiler>=0.60.0,<1.0.0

# Apple Silicon Specific (automatically detected)
# No special requirements - torch will use MPS backend

# Linux/CUDA Specific (optional, automatically detected)
# torch with CUDA support will be selected if available

# Exact versions used in paper (for perfect reproduction)
# Uncomment the following for exact version matching:
# torch==2.1.0
# transformers==4.35.2
# datasets==2.14.6
# scikit-learn==1.3.2
# numpy==1.24.3
# scipy==1.11.4
# pandas==2.0.3

# Installation Notes:
# 1. Install PyTorch first with appropriate backend:
#    - CPU: pip install torch --index-url https://download.pytorch.org/whl/cpu
#    - CUDA: pip install torch --index-url https://download.pytorch.torch/whl/cu118
#    - MPS: Default installation works on Apple Silicon
# 
# 2. Then install other requirements:
#    pip install -r requirements.txt
#
# 3. Download GloVe embeddings (Phase 1-3):
#    mkdir -p data/glove
#    cd data/glove
#    wget http://nlp.stanford.edu/data/glove.6B.zip
#    unzip glove.6B.zip
#
# 4. Download NLTK data (if using WordNet evaluation):
#    python -c "import nltk; nltk.download('wordnet')"